{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as kr\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from numpy.random import RandomState\n",
    "import scipy as scp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from itertools import product\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn import mixture\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RandomState(92) #To reproduce the same results each time we run this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset into a pandas DataFrame\n",
    "adult_data = pd.read_csv('adult_data.csv', na_values='?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all records with missing values\n",
    "adult_data.dropna(inplace=True)\n",
    "adult_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Data columns and their types\n",
    "adult_data.info()\n",
    "adult_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique values of each attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar plot of each attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,15))\n",
    "cols = 5\n",
    "rows = math.ceil(float(adult_data.shape[1]) / cols)\n",
    "for i, column in enumerate(adult_data.columns):\n",
    "    ax = fig.add_subplot(rows, cols, i + 1)\n",
    "    ax.set_title(column)\n",
    "    if adult_data.dtypes[column] == np.object:\n",
    "        adult_data[column].value_counts().plot(kind=\"bar\", axes=ax)\n",
    "    else:\n",
    "        adult_data[column].hist(axes=ax)\n",
    "        plt.xticks(rotation=\"vertical\")\n",
    "plt.subplots_adjust(hspace=0.9, wspace=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Income attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adult_data.income.value_counts())\n",
    "sns.countplot(x='income', data=adult_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = ((adult_data.income.value_counts()) * 100)/len(adult_data)\n",
    "print(percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Race attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_data['race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent1 = ((adult_data.race.value_counts()) * 100)/len(adult_data)\n",
    "percent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent2 = ((adult_data.groupby('race')['income'].value_counts()) * 100)/len(adult_data)\n",
    "percent2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting 'race' according to 'income':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race = round(pd.crosstab(adult_data.race, adult_data.income).div(pd.crosstab(adult_data.race, adult_data.income).apply(sum,1),0),2)\n",
    "race.sort_values(by = '>50K', inplace = True)\n",
    "ax = race.plot(kind ='bar', color=['#eca0d7','#64c774'], title = 'Proportion distribution across race levels', figsize = (10,8))\n",
    "ax.set_xlabel('Race level')\n",
    "ax.set_ylabel('Proportion of population')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The 'educational-num' column can be dropped since it's the same as'education'. And the columns 'capital-gain' and 'capital-loss' have more zeroes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_data.drop(['educational-num', 'capital-gain', 'capital-loss'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we replace 'income' values with 0 and 1, and the same for 'race. Thus, we have 0 for 'Black' and 1 for 'nonblacks'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_data.replace(['<=50K','>50K'],\n",
    "             [0,1], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_data.replace(['Black', 'White','Other','Amer-Indian-Eskimo','Asian-Pac-Islander'],\n",
    "             [0,1,1,1,1], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "One-hot encoding is the process of representing multi-class categorical features as binary features, one for each class. Although this process increases the dimensionality of the dataset, classification algorithms tend to work better on this format of data.\n",
    "\n",
    "I use one-hot encoding to represent all the categorical features in the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_col_1 =[ 'education', 'occupation',\n",
    "               'relationship','native-country','workclass','marital-status', 'gender'] \n",
    "\n",
    "adult = pd.get_dummies(adult_data, columns=category_col_1, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=adult.drop('fnlwgt',1)\n",
    "dataframe =dataframe[[c for c in dataframe if c not in ['income']] + ['income']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataframe.iloc[:, 0:95].values\n",
    "y = dataframe.iloc[:, 95].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "print (\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print (\"Testing set has {} samples.\".format(X_test.shape[0]))\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training with neural nets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASELINE SCENARIO\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Adding the input layer and the first hidden layer\n",
    "    model.add(Dense(output_dim = 70, activation = 'relu', input_dim = 93))\n",
    "    # Adding the second hidden layer\n",
    "    model.add(Dense(output_dim = 50, activation = 'relu'))\n",
    "    # Adding the output layer\n",
    "    model.add(Dense(output_dim = 1, activation = 'sigmoid'))\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=3e-4)\n",
    "    model.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, batch_size = 10, nb_epoch = 100, validation_split=0.2)\n",
    "    return model\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix for 'income':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "y_pred = np.where(pred>=0.5, 1,0)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn,fp,fn,tp = cm.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance measures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy: (tp + tn)/(tp + tn + fp + fn)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "#precision: tp/tp+fp\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "#recall: tp/tp+fn\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "#FNR: 1-recall\n",
    "fnr = 1 - recall\n",
    "print('FNR: %f' % fnr)\n",
    "#FPR: fp/fp+tn\n",
    "fpr = fp / (fp + tn)\n",
    "print('FPR: %f' % fpr)\n",
    "#f1: 2 tp/ (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score: %f' % f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC AUC score and Gini coefficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "\n",
    "plt.title('Receiver Operating Characteristic Curve')\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b',label='AUC = %0.2f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.1])\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "Gini_coefficient=2*roc_auc - 1\n",
    "print (\"Gini_coefficient =\",Gini_coefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix for 'Black' (0) individuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_rows = X_test[:,2]==0\n",
    "X_test_black = X_test[filter_rows,:]\n",
    "y_test_black = y_test[filter_rows]\n",
    "y_pred_black = model.predict(X_test_black)\n",
    "y_pred_b = np.where(y_pred_black>=0.5, 1,0)\n",
    "\n",
    "print(classification_report(y_test_black, y_pred_b))\n",
    "cmb = confusion_matrix(y_test_black, y_pred_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance measures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy: (tp + tn)/(tp + tn + fp + fn)\n",
    "accuracy = accuracy_score(y_test_black, y_pred_b)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "#precision: tp/tp+fp\n",
    "precision = precision_score(y_test_black, y_pred_b)\n",
    "print('Precision: %f' % precision)\n",
    "#recall: tp/tp+fn\n",
    "recall = recall_score(y_test_black, y_pred_b)\n",
    "print('Recall: %f' % recall)\n",
    "#FNR: 1-recall\n",
    "fnr = 1 - recall\n",
    "print('FNR: %f' % fnr)\n",
    "#FPR: fp/fp+tn\n",
    "fpr = fp / (fp + tn)\n",
    "print('FPR: %f' % fpr)\n",
    "#f1: 2 tp/ (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test_black, y_pred_b)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC AUC score and Gini coefficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test_black, y_pred_b)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "\n",
    "plt.title('Receiver Operating Characteristic Curve')\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b',label='AUC = %0.2f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.1])\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "Gini_coefficient=2*roc_auc - 1\n",
    "print (\"Gini_coefficient =\",Gini_coefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix for 'nonblack' (1) individuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_rows = X_test[:,2]==1\n",
    "X_test_nonblack = X_test[filter_rows,:]\n",
    "y_test_nonblack = y_test[filter_rows]\n",
    "y_pred_nonblack = model.predict(X_test_nonblack)\n",
    "y_pred_nb = np.where(y_pred_nonblack>=0.5, 1,0)\n",
    "\n",
    "print(classification_report(y_test_nonblack, y_pred_nb))\n",
    "cmnb = confusion_matrix(y_test_nonblack, y_pred_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance measures: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy: (tp + tn)/(tp + tn + fp + fn)\n",
    "accuracy = accuracy_score(y_test_nonblack, y_pred_nb)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "#precision: tp/tp+fp\n",
    "precision = precision_score(y_test_nonblack, y_pred_nb)\n",
    "print('Precision: %f' % precision)\n",
    "#recall: tp/tp+fn\n",
    "recall = recall_score(y_test_nonblack, y_pred_nb)\n",
    "print('Recall: %f' % recall)\n",
    "#FNR: 1-recall\n",
    "fnr = 1 - recall\n",
    "print('FNR: %f' % fnr)\n",
    "#FPR: fp/fp+tn\n",
    "fpr = fp / (fp + tn)\n",
    "print('FPR: %f' % fpr)\n",
    "#f1: 2 tp/ (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test_nonblack, y_pred_nb)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC AUC score and Gini coefficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test_nonblack, y_pred_nb)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "\n",
    "plt.title('Receiver Operating Characteristic Curve')\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b',label='AUC = %0.2f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.1])\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "Gini_coefficient=2*roc_auc - 1\n",
    "print (\"Gini_coefficient =\",Gini_coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
