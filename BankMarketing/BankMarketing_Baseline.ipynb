{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as kr\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from numpy.random import RandomState\n",
    "import scipy as scp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from itertools import product\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn import mixture\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RandomState(92) #To reproduce the same results each time we run this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset into a pandas DataFrame\n",
    "bm = pd.read_csv('bank-marketing_csv.csv', na_values='?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = bm.columns\n",
    "for c in col_names:\n",
    "\tbm[c] = bm[c].replace(\"?\", np.NaN)\n",
    "\n",
    "bm = bm.apply(lambda x:x.fillna(x.value_counts().index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique values of each attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar plot of each attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,15))\n",
    "cols = 5\n",
    "rows = math.ceil(float(bm.shape[1]) / cols)\n",
    "for i, column in enumerate(bm.columns):\n",
    "    ax = fig.add_subplot(rows, cols, i + 1)\n",
    "    ax.set_title(column)\n",
    "    if bm.dtypes[column] == np.object:\n",
    "        bm[column].value_counts().plot(kind=\"bar\", axes=ax)\n",
    "    else:\n",
    "        bm[column].hist(axes=ax)\n",
    "        plt.xticks(rotation=\"vertical\")\n",
    "plt.subplots_adjust(hspace=0.9, wspace=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm['Class'].replace(2, 0, inplace=True)\n",
    "bm['Class'].replace(1, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting 'Marital status' according to term deposit class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bm.groupby('V3')['Class'].value_counts().unstack('Class').plot.bar(color=['#deb887','#8b4513'], width=1)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm.replace(['divorced','married','single'],\n",
    "             [0,1,1], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "One-hot encoding is the process of representing multi-class categorical features as binary features, one for each class. Although this process increases the dimensionality of the dataset, classification algorithms tend to work better on this format of data.\n",
    "\n",
    "I use one-hot encoding to represent all the categorical features in the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_col_1 =[ 'V2', 'V4',\n",
    "               'V5','V7','V8','V9', 'V11', 'V16'] \n",
    "\n",
    "bm1 = pd.get_dummies(bm, columns=category_col_1, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(bm1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [i for i in range(m) if i != 8]\n",
    "# idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bm1.iloc[:, idx].values\n",
    "y = bm1.iloc[:, 8].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "print (\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print (\"Testing set has {} samples.\".format(X_test.shape[0]))\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training with neural nets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# BASELINE SCENARIO\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Adding the input layer and the first hidden layer\n",
    "    model.add(Dense(output_dim = 45, activation = 'relu', input_dim = 51))\n",
    "    # Adding the second hidden layer\n",
    "    model.add(Dense(output_dim = 30, activation = 'relu'))\n",
    "    # Adding the output layer\n",
    "    model.add(Dense(output_dim = 1, activation = 'sigmoid'))\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=3e-4)\n",
    "    model.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, batch_size = 10, nb_epoch = 100, validation_split=0.2)\n",
    "    return model\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix for Divorced clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_rows = X_test[:,3]==0\n",
    "X_test_div = X_test[filter_rows,:]\n",
    "y_test_div = y_test[filter_rows]\n",
    "y_pred_div = model.predict(X_test_div)\n",
    "y_pred_d = np.where(y_pred_div>=0.5, 1,0)\n",
    "\n",
    "print(classification_report(y_test_div, y_pred_d))\n",
    "cm_div = confusion_matrix(y_test_div, y_pred_b)\n",
    "tn,fp,fn,tp = cm_div.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance measures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy: (tp + tn)/(tp + tn + fp + fn)\n",
    "accuracy = accuracy_score(y_test_div, y_pred_d)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "#precision: tp/tp+fp\n",
    "precision = precision_score(y_test_div, y_pred_d)\n",
    "print('Precision: %f' % precision)\n",
    "#recall: tp/tp+fn\n",
    "recall = recall_score(y_test_div, y_pred_d)\n",
    "print('Recall: %f' % recall)\n",
    "#FNR: 1-recall\n",
    "fnr = 1 - recall\n",
    "print('FNR: %f' % fnr)\n",
    "#FPR: fp/fp+tn\n",
    "fpr = fp / (fp + tn)\n",
    "print('FPR: %f' % fpr)\n",
    "#f1: 2 tp/ (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test_div, y_pred_d)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC AUC score and Gini coefficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test_div, y_pred_d)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "\n",
    "plt.title('Receiver Operating Characteristic Curve')\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b',label='AUC = %0.2f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.1])\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "Gini_coefficient=2*roc_auc - 1\n",
    "print (\"Gini_coefficient =\",Gini_coefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix for 'nonblack' (1) individuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_rows = X_test[:,2]==1\n",
    "X_test_nd = X_test[filter_rows,:]\n",
    "y_test_nd = y_test[filter_rows]\n",
    "y_pred_ndiv = model.predict(X_test_nd)\n",
    "y_pred_nd = np.where(y_pred_ndiv>=0.5, 1,0)\n",
    "\n",
    "print(classification_report(y_test_nd, y_pred_nd))\n",
    "cmnd = confusion_matrix(y_test_nd, y_pred_nd)\n",
    "tn,fp,fn,tp = cmnd.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance measures: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy: (tp + tn)/(tp + tn + fp + fn)\n",
    "accuracy = accuracy_score(y_test_nd, y_pred_nd)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "#precision: tp/tp+fp\n",
    "precision = precision_score(y_test_nd, y_pred_nd)\n",
    "print('Precision: %f' % precision)\n",
    "#recall: tp/tp+fn\n",
    "recall = recall_score(y_test_nd, y_pred_nd)\n",
    "print('Recall: %f' % recall)\n",
    "#FNR: 1-recall\n",
    "fnr = 1 - recall\n",
    "print('FNR: %f' % fnr)\n",
    "#FPR: fp/fp+tn\n",
    "fpr = fp / (fp + tn)\n",
    "print('FPR: %f' % fpr)\n",
    "#f1: 2 tp/ (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test_nd, y_pred_nd)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC AUC score and Gini coefficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test_nd, y_pred_nd)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "\n",
    "plt.title('Receiver Operating Characteristic Curve')\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b',label='AUC = %0.2f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.1])\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "Gini_coefficient=2*roc_auc - 1\n",
    "print (\"Gini_coefficient =\",Gini_coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
